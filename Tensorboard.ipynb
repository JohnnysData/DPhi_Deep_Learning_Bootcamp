{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Tensorboard in 5 mins.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhwRyIzuqsrD",
        "colab_type": "text"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56V5oun18ZdZ",
        "colab_type": "text"
      },
      "source": [
        "**Visualization is the key to get the quick solution.**\n",
        "\n",
        "Tensorboard: Visualization toolkit of tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKFZHCkZDZua",
        "colab_type": "text"
      },
      "source": [
        "[Check out Video for explanation](https://www.youtube.com/watch?v=Uzkhn5ENJzQ&feature=youtu.be)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKTboSaPds2z",
        "colab_type": "text"
      },
      "source": [
        "To be able to us ethe tensorboard we have to first load the tensorboard extension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B95Hb6YVgPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c9e9e8e-267d-401a-d26e-40e78ad227de"
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA4SlJP2d4C9",
        "colab_type": "text"
      },
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wqSAZExy6xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wymif2oHcYsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2281cbcd-ce1c-451d-c599-7c8de7f81408"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4D2_II8eJT_",
        "colab_type": "text"
      },
      "source": [
        "Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-DHsby18cot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Loading the train and test dataset\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  #Normalizing"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzWrgXFMuP_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating new sequential model with a single dropout layer\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),  # First layer - a flatten layer which will take the input images of shape 28,28 and convert it into a single long vector.\n",
        "  tf.keras.layers.Dense(512, activation='relu'),  # Second layer - dense layer with 512 neurons\n",
        "  tf.keras.layers.Dropout(0.2),                   # Dropout layer with a dropout rate of 0.2\n",
        "  tf.keras.layers.Dense(10, activation='softmax') # Final output layer - dense layer with 10 neurons with the softmax activation function\n",
        "])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2y0emgSupkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "2afaac46-771b-4375-acaa-868fce511dbf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlMu1mNGpBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "9fd19447-00f4-4a3c-abd8-2b24ed5ad030"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adagrad',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# To be able to visualize the training data with the tensorboard we have to enable it iwth the use of 'tf.keras.callbacks.TensorBoard'\n",
        "# With this we will be able to save the logs which we can further use to create the visualization.\n",
        "\n",
        "# Before calling the fit on the data, specify the path and folder name in which it should be saved.\n",
        "# This will place logs in a time stamped subdirectory which we can use to access at a later time\n",
        "\n",
        "path = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Configure the tensorboard call back as\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=path, histogram_freq=1)  # log_dir: path where it should be saved\n",
        "                                                                                       # histogram computation for every epoch\n",
        "# performing the fit on the data\n",
        "model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=20, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "   1/1875 [..............................] - ETA: 0s - loss: 0.1394 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.0344s). Check your callbacks.\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1805 - accuracy: 0.9493 - val_loss: 0.1667 - val_accuracy: 0.9535\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1771 - accuracy: 0.9498 - val_loss: 0.1635 - val_accuracy: 0.9539\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1738 - accuracy: 0.9515 - val_loss: 0.1610 - val_accuracy: 0.9538\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1706 - accuracy: 0.9516 - val_loss: 0.1587 - val_accuracy: 0.9557\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1687 - accuracy: 0.9525 - val_loss: 0.1569 - val_accuracy: 0.9561\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1655 - accuracy: 0.9537 - val_loss: 0.1547 - val_accuracy: 0.9561\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1641 - accuracy: 0.9543 - val_loss: 0.1530 - val_accuracy: 0.9565\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1618 - accuracy: 0.9550 - val_loss: 0.1516 - val_accuracy: 0.9575\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1600 - accuracy: 0.9551 - val_loss: 0.1497 - val_accuracy: 0.9579\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1581 - accuracy: 0.9554 - val_loss: 0.1482 - val_accuracy: 0.9578\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1565 - accuracy: 0.9557 - val_loss: 0.1469 - val_accuracy: 0.9580\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1539 - accuracy: 0.9567 - val_loss: 0.1453 - val_accuracy: 0.9591\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1532 - accuracy: 0.9569 - val_loss: 0.1440 - val_accuracy: 0.9591\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1515 - accuracy: 0.9578 - val_loss: 0.1430 - val_accuracy: 0.9594\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1500 - accuracy: 0.9578 - val_loss: 0.1416 - val_accuracy: 0.9595\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1490 - accuracy: 0.9578 - val_loss: 0.1403 - val_accuracy: 0.9605\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1476 - accuracy: 0.9588 - val_loss: 0.1395 - val_accuracy: 0.9611\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1454 - accuracy: 0.9592 - val_loss: 0.1383 - val_accuracy: 0.9613\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1442 - accuracy: 0.9597 - val_loss: 0.1371 - val_accuracy: 0.9620\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1430 - accuracy: 0.9603 - val_loss: 0.1360 - val_accuracy: 0.9612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0dd01dcc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V806v23XbFAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca3b90eb-db19-464f-930d-e8a74957ebd8"
      },
      "source": [
        "!rm -rf ./logs/"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: rm -rf ./logs/: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjvStJlmJ-DU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "c5778e8f-043b-4965-9b21-48f63a4e6e9a"
      },
      "source": [
        "%tensorboard --logdir logs\\\\fit"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6008, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}